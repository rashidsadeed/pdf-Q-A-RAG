directories:
  data_directory: data/docs
  persist_directory: data/vectordb/processed/chroma/

embedding_model_config:
  model: "models/embedding-001"  # Google Gemini embedding model

llm_config:
  model: "gemini-1.5-pro"  # Google Gemini Chat Model
  temperature: 0.5

splitter_config:
  chunk_size: 800
  chunk_overlap: 200

retrieval_config:
  k: 3  # Number of results to retrieve

serve:
  port: 8000
